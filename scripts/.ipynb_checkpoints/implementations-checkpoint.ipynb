{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T13:10:35.849657Z",
     "start_time": "2019-10-25T13:10:35.793835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from proj1_helpers import *\n",
    "from implementations import *\n",
    "from tests import *\n",
    "from preprocessing import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outline of the pipeline\n",
    "## Import data\n",
    "+ Import raw data. Split original train data into out test and train sets.\n",
    "## Preprocessing\n",
    "+ The file `preprocessing.py` is imported and contains functions to clean (impute with mean), remove columns, standardize and do PCA.\n",
    "+ Preprocess train and test data separately (you can define the number of principal components used with the max_comp parameter. Defaults to 30).\n",
    "## Apply Model\n",
    "+ Apply your preferred model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T12:45:32.399348Z",
     "start_time": "2019-10-25T12:45:03.569779Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read train_y=LABELS, train_x=FEATURES and train_id=EVENT_IDS from dataset.\n",
    "subsamp = False\n",
    "y, x, id_ = load_csv_data('../data/train.csv', sub_sample=subsamp)\n",
    "y_out_test, x_out_test, id_out_test = load_csv_data('../data/test.csv', sub_sample=subsamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T10:48:20.858061Z",
     "start_time": "2019-10-25T10:48:14.840270Z"
    }
   },
   "outputs": [],
   "source": [
    "features = np.loadtxt('../data/train.csv', dtype=str, delimiter=',')[0,2:]\n",
    "def show_PC_explicit(features):\n",
    "    import sympy as sy\n",
    "    features_sym = [sy.symbols(f, real=True, positive=True) for f in features]\n",
    "    display(np.array(features_sym).dot(np.around(transform_train, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:15:52.507688Z",
     "start_time": "2019-10-25T17:15:51.960338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 24) (200000, 24)\n"
     ]
    }
   ],
   "source": [
    "clean = True\n",
    "dopca = False\n",
    "remove_cols = True\n",
    "cols = (4, 5, 6, 12, 26, 27, 28)\n",
    "#cols=(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28)\n",
    "max_comp = 30  # For cleaning, and no removing cols\n",
    "\n",
    "x_train, y_train, x_test, y_test = split_data(x, y, ratio=0.80, seed=10)\n",
    "y_train, x_train, x_train_mean, x_train_var, transform_train, eigenvals_train = preprocess(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    clean=clean,\n",
    "    dopca=dopca,\n",
    "    max_comp=max_comp,\n",
    "    remove_cols=remove_cols,\n",
    "    cols=cols)\n",
    "y_test, x_test, x_test_mean, x_test_var, transform_test, eigenvals_test = preprocess(\n",
    "    x_test,\n",
    "    y_test,\n",
    "    clean=clean,\n",
    "    dopca=dopca,\n",
    "    max_comp=max_comp,\n",
    "    remove_cols=remove_cols,\n",
    "    cols=cols)\n",
    "print(x_test.shape, x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:02:49.362611Z",
     "start_time": "2019-10-25T17:02:43.769620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 241), (50000, 241))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "degree = 10\n",
    "# Build data matrix with feature expansion\n",
    "tx_train = build_poly(x_train, degree)\n",
    "tx_test = build_poly(x_test, degree)\n",
    "tx_train.shape, tx_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T10:56:41.076423Z",
     "start_time": "2019-10-25T10:56:26.927938Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.730\n",
      "Test loss = 0.353\n",
      "Train loss = 0.348\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([0] * tx_train.shape[1])\n",
    "max_iter_gd = 500\n",
    "gamma_gd = 1e-3\n",
    "w_gd, loss_gd = least_squares_GD(y_train,\n",
    "                                 tx_train,\n",
    "                                 w_init,\n",
    "                                 max_iter_gd,\n",
    "                                 gamma_gd,\n",
    "                                 pr=False,\n",
    "                                 adapt_gamma=False,\n",
    "                                 kind='mse',\n",
    "                                accel=False)\n",
    "gd_prediction = predict_labels(w_gd, tx_test)\n",
    "acc_gd = accuracy_ratio(gd_prediction, y_test)\n",
    "print('Accuracy ratio = %.3f' % acc_gd)\n",
    "print('Test loss = %.3f' % compute_loss(y_test, tx_test, w_gd))\n",
    "print('Train loss = %.3f' % loss_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:37:03.486835Z",
     "start_time": "2019-10-17T12:37:03.480662Z"
    },
    "hidden": true
   },
   "source": [
    "np.savetxt('../data/w_gd_acc.dat', w_gd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T11:00:36.111308Z",
     "start_time": "2019-10-25T10:57:02.385613Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.64\n",
      "Test loss = 4.88e-01\n",
      "Train loss = 4.89e-01\n"
     ]
    }
   ],
   "source": [
    "w_init = np.array([0] * tx_train.shape[1])\n",
    "max_iter_sgd = 500\n",
    "gamma_sgd = 1e-5\n",
    "batch_size = 1\n",
    "\n",
    "w_sgd, loss_sgd = least_squares_SGD(y_train,\n",
    "                                    tx_train,\n",
    "                                    w_init,\n",
    "                                    batch_size,\n",
    "                                    max_iter_sgd,\n",
    "                                    gamma_sgd,\n",
    "                                    pr=False,\n",
    "                                    adapt_gamma=False,\n",
    "                                    choose_best=True)\n",
    "sgd_prediction = predict_labels(w_sgd, tx_test)\n",
    "acc_sgd = accuracy_ratio(sgd_prediction, y_test)\n",
    "print('Accuracy ratio = %.2f' % acc_sgd)\n",
    "print('Test loss = %.2e' % compute_loss(y_test, tx_test, w_sgd))\n",
    "print('Train loss = %.2e' % loss_sgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T11:02:55.087004Z",
     "start_time": "2019-10-25T11:02:54.998793Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.55\n",
      "Train loss = 0.32\n",
      "Test loss = 1.24e+01\n"
     ]
    }
   ],
   "source": [
    "w_lsq, loss_lsq = least_squares(y_train, tx_train)\n",
    "lsq_prediction = predict_labels(w_lsq, tx_test)\n",
    "acc_lsq = accuracy_ratio(lsq_prediction, y_test)\n",
    "print('Accuracy ratio = %.2f' % acc_lsq)\n",
    "print('Train loss = %.2f' % loss_lsq)\n",
    "print('Test loss = %.2e' % compute_loss(y_test, tx_test, w_lsq))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-17T12:45:30.271461Z",
     "start_time": "2019-10-17T12:45:30.267909Z"
    },
    "hidden": true
   },
   "source": [
    "np.savetxt('../data/w_lsq.dat', w_lsq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:11:12.848982Z",
     "start_time": "2019-10-25T17:11:12.381338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.814\n",
      "Test loss = 241364.703\n",
      "Train loss = 0.280\n"
     ]
    }
   ],
   "source": [
    "lambda_rr = 2.7e-3\n",
    "w_rr, loss_rr = ridge_regression(y_train, tx_train, lambda_rr)\n",
    "rr_prediction = predict_labels(w_rr, tx_test)\n",
    "acc_rr = accuracy_ratio(rr_prediction, y_test)\n",
    "print('Accuracy ratio = %.3f'%acc_rr)\n",
    "print('Test loss = %.3f'%compute_loss(y_test, tx_test, w_rr))\n",
    "print('Train loss = %.3f'%loss_rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-18T15:18:22.322364Z",
     "start_time": "2019-10-18T15:18:22.309384Z"
    }
   },
   "source": [
    "np.savetxt('../data/w_rr.dat', w_rr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T11:22:42.956505Z",
     "start_time": "2019-10-25T11:18:51.825658Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.783\n",
      "Test loss = 1167.278\n",
      "Train loss = 113561.140\n"
     ]
    }
   ],
   "source": [
    "y_train_log = minus_one_2_zero(y_train)\n",
    "y_test_log = minus_one_2_zero(y_test)\n",
    "\n",
    "\n",
    "w_init = np.array([0] * tx_train.shape[1])\n",
    "max_iter_lrgd = 500\n",
    "gamma_lrgd = 1e-8\n",
    "w_lrgd, loss_lrgd = logistic_regression(y_train_log,\n",
    "                                        tx_train,\n",
    "                                        w_init,\n",
    "                                        max_iter_lrgd,\n",
    "                                        gamma_lrgd,\n",
    "                                        pr=False,\n",
    "                                        adapt_gamma=False,\n",
    "                                       accel=False)\n",
    "\n",
    "lrgd_prediction = predict_labels(w_lrgd, tx_test)\n",
    "acc_lrgd = accuracy_ratio(lrgd_prediction, y_test)\n",
    "\n",
    "print('Accuracy ratio = %.3f' % acc_lrgd)\n",
    "print('Test loss = %.3f' % compute_loss_logistic(y_test_log, tx_test, w_lrgd))\n",
    "print('Train loss = %.3f' % loss_lrgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T11:23:07.210851Z",
     "start_time": "2019-10-25T11:22:42.961874Z"
    },
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.726\n",
      "Test loss = 1343.362\n",
      "Train loss = 131688.258\n"
     ]
    }
   ],
   "source": [
    "lambda_rlrgd = 50\n",
    "gamma_rlrgd = 1e-8\n",
    "max_iter_rlrgd = 500\n",
    "lambda_rr = 2e-4\n",
    "\n",
    "w_rlrgd, loss_rlrgd = reg_logistic_regression(y_train_log,\n",
    "                                              tx_train,\n",
    "                                              lambda_rlrgd,\n",
    "                                              w_init,\n",
    "                                              max_iter_rlrgd,\n",
    "                                              gamma_rlrgd,\n",
    "                                              pr=False,\n",
    "                                              adapt_gamma=False, \n",
    "                                              accel=False)\n",
    "rlrgd_prediction = predict_labels(w_rlrgd, tx_test)\n",
    "acc_rlrgd = accuracy_ratio(rlrgd_prediction, y_test)\n",
    "print('Accuracy ratio = %.3f' % acc_rlrgd)\n",
    "print('Test loss = %.3f' % compute_loss_logistic(y_test_log, tx_test, w_rlrgd))\n",
    "print('Train loss = %.3f' % loss_rlrgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-25T17:09:19.275505Z",
     "start_time": "2019-10-25T17:05:12.740268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using method ridge_regression\n",
      "Using lambda = 1.0e-07\n",
      "Using lambda = 1.3e-06\n",
      "Using lambda = 1.7e-05\n",
      "Using lambda = 2.2e-04\n",
      "Using lambda = 2.8e-03\n",
      "Using lambda = 3.6e-02\n",
      "Using lambda = 4.6e-01\n",
      "Using lambda = 6.0e+00\n",
      "Using lambda = 7.7e+01\n",
      "Using lambda = 1.0e+03\n",
      "Best lambda from error: 1.00e+03\n",
      "Best lambda from accuracy: 2.78e-03\n"
     ]
    }
   ],
   "source": [
    "cross_validation_demo(x, y, ridge_regression, args_rr, k_fold=4, degree = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-10-25T17:29:22.818Z"
    }
   },
   "outputs": [],
   "source": [
    "subsamp = False\n",
    "y, x, id_ = load_csv_data('../data/train.csv', sub_sample=subsamp)\n",
    "y_out_test, x_out_test, id_out_test = load_csv_data('../data/test.csv', sub_sample=subsamp)\n",
    "clean = True\n",
    "dopca = False\n",
    "remove_cols = False\n",
    "cols = (4, 5, 6, 12, 26, 27, 28)\n",
    "#cols=(0, 4, 5, 6, 12, 23, 24, 25, 26, 27, 28)\n",
    "max_comp = 30  # For cleaning, and no removing cols\n",
    "\n",
    "y_train, x_train, x_train_mean, x_train_var, transform_train, eigenvals_train = preprocess(\n",
    "    x,\n",
    "    y,\n",
    "    clean=clean,\n",
    "    dopca=dopca,\n",
    "    max_comp=max_comp,\n",
    "    remove_cols=remove_cols,\n",
    "    cols=cols)\n",
    "y_test, x_test, x_test_mean, x_test_var, transform_test, eigenvals_test = preprocess(\n",
    "    x_out_test,\n",
    "    y_out_test,\n",
    "    clean=clean,\n",
    "    dopca=dopca,\n",
    "    max_comp=max_comp,\n",
    "    remove_cols=remove_cols,\n",
    "    cols=cols)\n",
    "print(x_test.shape, x_train.shape)\n",
    "degree = 10\n",
    "# Build data matrix with feature expansion\n",
    "tx_train = build_poly(x_train, degree)\n",
    "tx_test = build_poly(x_test, degree)\n",
    "print(tx_train.shape, tx_test.shape)\n",
    "\n",
    "lambda_rr = 2.78e-3\n",
    "w_rr, loss_rr = ridge_regression(y_train, tx_train, lambda_rr)\n",
    "rr_prediction = predict_labels(w_rr, tx_test)\n",
    "print('Train loss = %.3f'%loss_rr)\n",
    "create_csv_submission(id_out_test, predict_labels(w_rr, tx_test) , '../results/rr_pred_deg10_cl1_pc0_rmcol0.csv')\n",
    "#create_csv_submission(id_out_test, predict_labels(w_sgd, tx_out) , '../results/sgd_pred_noadapt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T10:12:29.041410Z",
     "start_time": "2019-10-21T10:12:08.532Z"
    },
    "code_folding": [
     0,
     38
    ]
   },
   "outputs": [],
   "source": [
    "def bias_variance_decomposition_visualization(degrees, rmse_tr, rmse_te):\n",
    "    \"\"\"visualize the bias variance decomposition.\"\"\"\n",
    "    rmse_tr_mean = np.expand_dims(np.mean(rmse_tr, axis=0), axis=0)\n",
    "    rmse_te_mean = np.expand_dims(np.mean(rmse_te, axis=0), axis=0)\n",
    "    print(rmse_te_mean, rmse_tr_mean)\n",
    "    plt.plot(degrees,\n",
    "             rmse_tr.T,\n",
    "             'b',\n",
    "             linestyle=\"-\",\n",
    "             color=([0.7, 0.7, 1]),\n",
    "             label='train',\n",
    "             linewidth=0.3)\n",
    "    plt.plot(degrees,\n",
    "             rmse_te.T,\n",
    "             'r',\n",
    "             linestyle=\"-\",\n",
    "             color=[1, 0.7, 0.7],\n",
    "             label='test',\n",
    "             linewidth=0.3)\n",
    "    plt.plot(degrees,\n",
    "             rmse_tr_mean.T,\n",
    "             'b',\n",
    "             linestyle=\"-\",\n",
    "             label='train',\n",
    "             linewidth=3)\n",
    "    plt.plot(degrees,\n",
    "             rmse_te_mean.T,\n",
    "             'r',\n",
    "             linestyle=\"-\",\n",
    "             label='test',\n",
    "             linewidth=3)\n",
    "    plt.ylim(0.7, 1)\n",
    "    plt.xlabel(\"degree\")\n",
    "    plt.ylabel(\"error\")\n",
    "    plt.title(\"Bias-Variance Decomposition\")\n",
    "    plt.savefig(\"bias_variance\")\n",
    "\n",
    "\n",
    "def bias_variance_demo():\n",
    "    \"\"\"The entry.\"\"\"\n",
    "    # define parameters\n",
    "    seeds = range(100)\n",
    "    ratio_train = 0.5\n",
    "    degrees = range(1, 8)\n",
    "    # define list to store the variable\n",
    "    rmse_tr = np.empty((len(seeds), len(degrees)))\n",
    "    rmse_te = np.empty((len(seeds), len(degrees)))\n",
    "    for index_seed, seed in enumerate(seeds):\n",
    "        np.random.seed(seed)\n",
    "        # split data with a specific seed\n",
    "        x_train, y_train, x_test, y_test = split_data(x, y, ratio_train, seed)\n",
    "        x_train_std = standardize(x_train)[0]\n",
    "        x_test_std = standardize(x_test)[0]\n",
    "        for index_degrees, degree in enumerate(degrees):\n",
    "            tx_train = build_poly(x_train_std, degree)\n",
    "            tx_test = build_poly(x_test_std, degree)\n",
    "            weight, loss_tr = ridge_regression(y_train, tx_train, 1.89e-05 )\n",
    "            loss_te = compute_loss(y_test, tx_test, weight, kind='mse')\n",
    "            rmse_tr[index_seed, index_degrees] = np.sqrt(2 * loss_tr)\n",
    "            rmse_te[index_seed, index_degrees] = np.sqrt(2 * loss_te)\n",
    "    bias_variance_decomposition_visualization(degrees, rmse_tr, rmse_te)\n",
    "\n",
    "\n",
    "bias_variance_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Logistic regression NEW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-24T12:59:38.503443Z",
     "start_time": "2019-10-24T12:59:37.799725Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy ratio = 0.803\n",
      "Test loss = 849.962\n",
      "Train loss = 3368.144\n",
      "[-0.11252881  0.56249914 -0.70734386  0.07221543  0.21124136  0.47648587\n",
      " -0.11628118  0.26375989 -0.35192631  0.16578181  0.59773594 -0.00686058\n",
      "  0.03923464  0.3522235   0.07278065  0.08853583 -0.0550296  -0.06087281\n",
      " -0.06022777  0.01697526  0.11249201 -0.90652965  0.13185629 -0.8545514\n",
      "  0.00394634 -0.31464538  0.03551931  0.02057922  0.04513402  0.40097713\n",
      " -0.0549146  -0.09740322  0.01470469  0.00540386 -0.26994535  0.03664979\n",
      "  0.10355341 -0.03171698 -0.21074765 -0.11798162  0.02071415]\n"
     ]
    }
   ],
   "source": [
    "w_init = np.zeros(tx_train.shape[1])\n",
    "max_iter = 1000\n",
    "gamma = 1e-5\n",
    "w_lrgd, loss_lrgd = logistic_regression(y_train,\n",
    "                                        tx_train,\n",
    "                                        w_init,\n",
    "                                        max_iter,\n",
    "                                        gamma,\n",
    "                                        pr=False,\n",
    "                                        adapt_gamma=False,\n",
    "                                       accel=False,\n",
    "                                       new=True)\n",
    "\n",
    "lrgd_prediction = predict_labels(w_lrgd, tx_test)\n",
    "\n",
    "acc_lrgd = accuracy_ratio(lrgd_prediction, y_test)\n",
    "\n",
    "print('Accuracy ratio = %.3f' % acc_lrgd)\n",
    "print('Test loss = %.3f' % compute_loss_logistic_new(y_test, tx_test, w_lrgd))\n",
    "print('Train loss = %.3f' % loss_lrgd)\n",
    "print((w_lrgd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-23T20:35:14.830175Z",
     "start_time": "2019-10-23T20:35:09.813385Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "lambda_ = 100\n",
    "gamma = 5e-6\n",
    "w_rlrgd, loss_rlrgd = reg_logistic_regression(y_train,\n",
    "                                              tx_train,\n",
    "                                              lambda_,\n",
    "                                              w_init,\n",
    "                                              max_iter,\n",
    "                                              gamma,\n",
    "                                              pr=True,\n",
    "                                              adapt_gamma=False, \n",
    "                                              accel=False,\n",
    "                                              new = True)\n",
    "rlrgd_prediction = predict_labels(w_rlrgd, tx_test)\n",
    "acc_rlrgd = accuracy_ratio(rlrgd_prediction, y_test)\n",
    "print('Accuracy ratio = %.3f' % acc_rlrgd)\n",
    "print('Test loss = %.3f' % compute_loss_logistic_new(y_test, tx_test, w_rlrgd))\n",
    "print('Train loss = %.3f' % loss_rlrgd)\n",
    "print((w_rlrgd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias-variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T11:40:49.132002Z",
     "start_time": "2019-10-21T11:40:11.716871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "\n",
    "    index = np.arange(k_indices.shape[0])\n",
    "    index_te = k\n",
    "    index_tr = index[index != index_te]\n",
    "\n",
    "    x_tr = x[np.ravel(k_indices[index_tr])]\n",
    "    x_te = x[k_indices[index_te]]\n",
    "    y_tr = y[np.ravel(k_indices[index_tr])]\n",
    "    y_te = y[k_indices[index_te]]\n",
    "    tx_tr = build_poly(x_tr, degree)\n",
    "    tx_te = build_poly(x_te, degree)\n",
    "\n",
    "    weight, loss_tr = ridge_regression(y_tr, tx_tr, lambda_)\n",
    "\n",
    "    loss_te = compute_loss(y_te, tx_te, weight)\n",
    "    accuracy = accuracy_ratio(predict_labels(weight, tx_test), y_test)\n",
    "    return loss_tr, loss_te, accuracy, weight\n",
    "\n",
    "\n",
    "def best_degree_lambda(y, x):\n",
    "    \"\"\"The entry.\"\"\"\n",
    "    # define parameters\n",
    "    seeds = range(20)\n",
    "    lambdas = np.logspace(-7, 0, 30)\n",
    "    k_fold = 5\n",
    "    ratio_train = 0.3\n",
    "    degrees = range(1, 5)\n",
    "\n",
    "    # define list to store the variable\n",
    "    rmse_te = np.empty((len(seeds), len(degrees)))\n",
    "    lambda_all = np.empty((len(seeds), len(degrees)))\n",
    "    variance_te = np.empty(len(degrees))\n",
    "    \n",
    "    for index_seed, seed in enumerate(seeds):\n",
    "        np.random.seed(seed)\n",
    "\n",
    "        x_tr, y_tr, x_te, y_te = split_data(x, y, ratio_train, seed)\n",
    "        y_tr, x_tr, _, _, _, _ = preprocess(x_train,\n",
    "                                            y_train,\n",
    "                                            clean=clean,\n",
    "                                            dopca=dopca,\n",
    "                                            max_comp=max_comp,\n",
    "                                            remove_cols=remove_cols,\n",
    "                                            cols=cols)\n",
    "        y_te, x_te, _, _, _, _ = preprocess(x_test,\n",
    "                                            y_test,\n",
    "                                            clean=clean,\n",
    "                                            dopca=dopca,\n",
    "                                            max_comp=max_comp,\n",
    "                                            remove_cols=remove_cols,\n",
    "                                            cols=cols)\n",
    "        k_indices = build_k_indices(y_tr, k_fold, seed)\n",
    "        for index_deg, deg in enumerate(degrees):\n",
    "            tx_te = build_poly(x_te, deg)\n",
    "            ws_lambda = []\n",
    "            loss_te_lambda = np.empty(len(lambdas))\n",
    "            loss_tr_lambda = np.empty(len(lambdas))\n",
    "            acc_lambda = np.empty(len(lambdas))\n",
    "            for index_l, lambda_ in enumerate(lambdas):\n",
    "                ws_k = []\n",
    "                loss_te_k = np.empty(k_fold)\n",
    "                loss_tr_k = np.empty(k_fold)\n",
    "                acc_k = np.empty(k_fold)\n",
    "                for k in range(k_fold):\n",
    "                    loss_tr_tmp, loss_te_tmp, acc_tmp, w_tmp = cross_validation(\n",
    "                        y_tr, x_tr, k_indices, k, lambda_, deg)\n",
    "                    loss_te_k[k] = loss_te_tmp\n",
    "                    loss_tr_k[k] = loss_tr_tmp\n",
    "                    ws_k.append(w_tmp)\n",
    "                loss_te_lambda[index_l] = np.mean(loss_te_k)\n",
    "                loss_tr_lambda[index_l] = np.mean(loss_tr_k)\n",
    "                ws_lambda.append(ws_k)\n",
    "\n",
    "            ind_opt_lambda = np.argmin(loss_te_lambda)\n",
    "            ws_opt = ws_lambda[ind_opt_lambda]\n",
    "\n",
    "            loss_te = np.mean(\n",
    "                [np.sqrt(2 * compute_loss(y_te, tx_te, w)) for w in ws_opt])\n",
    "            rmse_te[index_seed, index_deg] = loss_te\n",
    "            lambda_all[index_seed, index_deg] = lambdas[ind_opt_lambda]\n",
    "\n",
    "    variance_te = np.std(rmse_te, axis=0)\n",
    "\n",
    "    plt.figure(1)\n",
    "    plt.errorbar(degrees, np.mean(rmse_te, axis=0), yerr=variance_te)\n",
    "    plt.figure(2)\n",
    "    plt.errorbar(degrees,\n",
    "                 np.mean(lambda_all, axis=0),\n",
    "                 yerr=np.std(lambda_all, axis=0))\n",
    "    print(degrees[np.argmin(np.mean(rmse_te, axis=0))])\n",
    "    return np.mean(rmse_te, axis=0), variance_te\n",
    "    #plt.figure(2)\n",
    "    #plt.boxplot(rmse_te)\n",
    "\n",
    "\n",
    "rmse_CV, var_CV = best_degree_lambda(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-21T11:40:49.139000Z",
     "start_time": "2019-10-21T11:40:49.134296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.82530948, 0.81605139, 0.85528506, 1.15471421])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
